{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network validation\n",
    "This scripts is meant to validate that the designed vertex location match the real locations.\n",
    "\n",
    "The theoratical vertices are found in a network model as net.vertices.\n",
    "The real vertices are retrieved from a picture of the network suspended in a frame. The following steps are required to enable the comparison:\n",
    "- Conventional cameras have some distortion. (straight lines appear to be curved). The camera distortion can be found from a set of images of a checkerboard with known dimensions. The image is then undistorted.\n",
    "- Ideally, a picture of the network is taken exaclty orthogonal to the subject. The homography of the camera angle with respect to the frame is determined. The frame contains markers on a straight plane with known world coordinates. With the homography known an image can be warped such that it appears to take the frame exactly orthogonal to the frame.\n",
    "\n",
    "Finally, the vertices are selected in the image and they can be compared to their theoratical locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from src.network import Network_custom\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BYU_UW_root = r\"G:\\.shortcut-targets-by-id\\1k1B8zPb3T8H7y6x0irFZnzzmfQPHMRPx\\Illimited Lab Projects\\Research Projects\\Spiders\\BYU-UW\"\n",
    "# model_name  = 'Validation_structure_1'\n",
    "# model_name = 'VS_ring0.5_connectors0.8_center0.2_as1.5_asr1.5_s110'\n",
    "# model_name = 'unit_cell_loop_size_q_(1.5, 2, 0.7)'\n",
    "model_name = 'unit_cell_loop_size_q_(1.5, 2, 0.7)_10'\n",
    "# model_name = 'unit_cell_even_q_0.35'\n",
    "try:\n",
    "    net = Network_custom.load_network(os.path.join(BYU_UW_root, 'networks', model_name + '.pkl'))\n",
    "    rotate45 = False\n",
    "except:\n",
    "    net = Network_custom.load_network(os.path.join(BYU_UW_root, 'networks', model_name + '_net.pkl'))\n",
    "    rotate45 = True\n",
    "net.net_plot(color=True, elables = False, vlabels = True)\n",
    "\n",
    "picture_number = 2\n",
    "model_name_im = model_name + f\"_{picture_number}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a set of images of checker boards\n",
    "Internal camera and distortion parameters are determined of the camera. The process needs to be repeated when changing anything on the camera set up (lens/zoom/aperture/etc..). Make sure that auto-focus is off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkerboard_size = (8, 12)  # Number of inner corners per a chessboard row and column\n",
    "# square_size = 10 #6.85/(checkerboard_size[0]+1) * 0.0254\n",
    "\n",
    "# # Termination criteria for corner sub-pixel accuracy\n",
    "# criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# # Prepare object points based on the real-world dimensions of the checkerboard\n",
    "# objp = np.zeros((checkerboard_size[0] * checkerboard_size[1], 3), np.float32)\n",
    "# objp[:, :2] = np.mgrid[0:checkerboard_size[1], 0:checkerboard_size[0]].T.reshape(-1, 2)\n",
    "# objp *= square_size\n",
    "\n",
    "# # Arrays to store object points and image points from all the images\n",
    "# objpoints = []  # 3d points in real-world space\n",
    "# imgpoints = []  # 2d points in image plane\n",
    "\n",
    "# # Load images\n",
    "# # images = glob.glob(os.path.join(BYU_UW_root,'Calibration images/*.jpg' ))\n",
    "# images = glob.glob(os.path.join(BYU_UW_root,'Calibration images/new3/*.jpg' ))\n",
    "\n",
    "# for fname in images:\n",
    "#     img = cv2.imread(fname)\n",
    "#     img_shape = img.shape[:2]\n",
    "#     img_aspect_ratio = img_shape[1] / img_shape[0]\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Find the chessboard corners\n",
    "#     ret, corners = cv2.findChessboardCorners( \n",
    "#                     gray, (12, 8),  \n",
    "#                     cv2.CALIB_CB_ADAPTIVE_THRESH + \n",
    "#                     cv2.CALIB_CB_NORMALIZE_IMAGE) \n",
    "#     # If found, add object points, image points (after refining them)\n",
    "#     if ret:\n",
    "#         objpoints.append(objp.copy())\n",
    "#         corners2 = cv2.cornerSubPix(gray, corners, (31, 31), (-1, -1), criteria)\n",
    "#         imgpoints.append(corners2)\n",
    "\n",
    "#         # Draw and display the corners\n",
    "#         cv2.drawChessboardCorners(img, checkerboard_size, corners2, ret)\n",
    "#         # resized_image = cv2.resize(img, (400, int(400 / img_aspect_ratio)))\n",
    "#         cv2.imshow('img', img)\n",
    "#         # cv2.waitKey(1)\n",
    "        \n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# # Calibrate the camera\n",
    "# flags = cv2.CALIB_FIX_K3 + cv2.CALIB_FIX_K4 + cv2.CALIB_FIX_K5 + cv2.CALIB_FIX_K6\n",
    "# ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "#     objpoints, imgpoints, gray.shape[::-1], None, None, flags=flags\n",
    "# )\n",
    "# # Print the camera matrix and distortion coefficients\n",
    "# print(\"Camera matrix:\\n\", mtx)\n",
    "# print(\"Distortion coefficients:\\n\", dist)\n",
    "\n",
    "# # Check calibration results. A good mean projection error is <1.0\n",
    "# mean_error = 0\n",
    "# for i in range(len(objpoints)):\n",
    "#     imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "#     error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
    "#     mean_error += error\n",
    "# print(\"Mean reprojection error:\", mean_error / len(objpoints))\n",
    "\n",
    "# img = cv2.imread(images[-1])\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# ax[0].imshow(img)\n",
    "# ax[0].set_title('Original Image')\n",
    "# ax[1].imshow(cv2.undistort(img, mtx, dist))\n",
    "# ax[1].set_title('Undistorted Image')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import numpy as np\n",
    "# import os\n",
    "# mtx = np.array([[2.25105751e+04, 0.00000000e+00, 2.49549539e+03],\n",
    "#         [0.00000000e+00, 2.25183605e+04, 2.84911943e+03],\n",
    "#         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n",
    "\n",
    "# dist = np.array([[ 0.56985739,  1.09785385, -0.00920809,  0.02059732,  3.93628828]])\n",
    "\n",
    "mtx = np.array([[2.68908731e+04, 0.00000000e+00, 2.26405663e+03],\n",
    " [0.00000000e+00, 2.68576281e+04, 2.94945084e+03],\n",
    " [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n",
    "\n",
    "dist = np.array([[ 0.8429211,  -0.30036892, -0.00690671,  0.01086315,  0.        ]])\n",
    "\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# # === Load image ===\n",
    "image_name = model_name_im + \".jpg\"\n",
    "image_path = os.path.join(BYU_UW_root, 'measuerement images', image_name)\n",
    "original_image = plt.imread(image_path)\n",
    "height, width, _ = original_image.shape\n",
    "\n",
    "img_und = cv2.undistort(original_image, mtx, dist[:4])\n",
    "\n",
    "mean_img = (original_image + img_und) / 2\n",
    "mean_img = mean_img.astype(np.uint8)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(mean_img)\n",
    "\n",
    "\n",
    "checker_image_name = \"checkerboard0.JPG\"\n",
    "checker_image_path = os.path.join(BYU_UW_root, 'measuerement images', checker_image_name)\n",
    "checker_image = plt.imread(checker_image_path)\n",
    "\n",
    "checker_image_und = cv2.undistort(checker_image, mtx, dist[:4])\n",
    "\n",
    "checker_image_mean = (checker_image + checker_image_und) / 2\n",
    "checker_image_mean = checker_image_mean.astype(np.uint16)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(checker_image)\n",
    "\n",
    "\n",
    "original_image = img_und\n",
    "# checker_image = checker_image_und"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an image of the frame and click on the markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.widgets import Button\n",
    "# === State trackers ===\n",
    "rotation_state = [0]       # in degrees, e.g. 0, 90, 180, 270\n",
    "flip_ud_state = [False]    # vertical flip state\n",
    "image_displayed = [None]   # store current image\n",
    "ax = [None]                # access axis in handlers\n",
    "\n",
    "def apply_transform():\n",
    "    \"\"\"Apply rotation and flip to the original image and return the transformed image.\"\"\"\n",
    "    img = original_image.copy()\n",
    "    # Flip up-down if needed\n",
    "    if flip_ud_state[0]:\n",
    "        img = np.flipud(img)\n",
    "    # Rotate based on rotation_state\n",
    "    k = rotation_state[0] // 90\n",
    "    img = np.rot90(img, k=k)\n",
    "    return img\n",
    "\n",
    "def update_display():\n",
    "    ax[0].clear()\n",
    "    transformed = apply_transform()\n",
    "    ax[0].imshow(transformed)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(f\"Rot: {rotation_state[0]}Â°, FlipUD: {flip_ud_state[0]}\")\n",
    "    ax[0].figure.canvas.draw()\n",
    "\n",
    "def rotate_plus(event):\n",
    "    rotation_state[0] = (rotation_state[0] + 90) % 360\n",
    "    update_display()\n",
    "\n",
    "def rotate_minus(event):\n",
    "    rotation_state[0] = (rotation_state[0] - 90) % 360\n",
    "    update_display()\n",
    "\n",
    "def flip_ud(event):\n",
    "    flip_ud_state[0] = not flip_ud_state[0]\n",
    "    update_display()\n",
    "\n",
    "def on_close(event):\n",
    "    global original_image\n",
    "    original_image = apply_transform()\n",
    "    height, width, _ = original_image.shape\n",
    "    print(\"Image window closed. `original_image` updated with final transformation.\")\n",
    "\n",
    "# === Plot image ===\n",
    "fig, main_ax = plt.subplots(figsize=(12, 12))\n",
    "ax[0] = main_ax\n",
    "fig.canvas.manager.set_window_title(\"Image Viewer\")\n",
    "image_displayed[0] = main_ax.imshow(apply_transform())\n",
    "main_ax.axis(\"off\")\n",
    "main_ax.set_title(f\"Rot: {rotation_state[0]}Â°, FlipUD: {flip_ud_state[0]}\")\n",
    "# Connect close event\n",
    "fig.canvas.mpl_connect(\"close_event\", on_close)\n",
    "\n",
    "# === Buttons ===\n",
    "button_fig, _ = plt.subplots(figsize=(3, 2))\n",
    "button_fig.canvas.manager.set_window_title(\"Controls\")\n",
    "\n",
    "ax_rotp = plt.axes([0.1, 0.6, 0.8, 0.25])\n",
    "ax_rotm = plt.axes([0.1, 0.35, 0.8, 0.25])\n",
    "ax_flip = plt.axes([0.1, 0.1, 0.8, 0.25])\n",
    "\n",
    "btn_rotp = Button(ax_rotp, \"+90Â°\")\n",
    "btn_rotm = Button(ax_rotm, \"-90Â°\")\n",
    "btn_flip = Button(ax_flip, \"Flip Up/Down\")\n",
    "\n",
    "btn_rotp.on_clicked(rotate_plus)\n",
    "btn_rotm.on_clicked(rotate_minus)\n",
    "btn_flip.on_clicked(flip_ud)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image window closed. `original_image` updated with final transformation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initial axis limits\n",
    "xlim_init, ylim_init = (0, width), (height, 0)\n",
    "points = []  # Store clicked points\n",
    "def on_click(event):\n",
    "    \"\"\"Reset view when clicking anywhere in the figure.\"\"\"\n",
    "    if event.button == 1:  # Left mouse button\n",
    "        points.append((event.xdata, event.ydata))\n",
    "        ax.plot(event.xdata, event.ydata, 'r.', label='real vertices')\n",
    "        ax.set_xlim(xlim_init)\n",
    "        ax.set_ylim(ylim_init)\n",
    "        ax.figure.canvas.draw()\n",
    "\n",
    "def on_scroll(event):\n",
    "    \"\"\"Zoom in/out at mouse position using the scroll wheel.\"\"\"\n",
    "    scale_factor = 1.3  # Zoom speed\n",
    "    xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "\n",
    "    if event.step > 0:  # Zoom in\n",
    "        xlim_new = (event.xdata - (event.xdata - xlim[0]) / scale_factor,\n",
    "                    event.xdata + (xlim[1] - event.xdata) / scale_factor)\n",
    "        ylim_new = (event.ydata - (event.ydata - ylim[0]) / scale_factor,\n",
    "                    event.ydata + (ylim[1] - event.ydata) / scale_factor)\n",
    "    else:  # Zoom out\n",
    "        xlim_new = (event.xdata - (event.xdata - xlim[0]) * scale_factor,\n",
    "                    event.xdata + (xlim[1] - event.xdata) * scale_factor)\n",
    "        ylim_new = (event.ydata - (event.ydata - ylim[0]) * scale_factor,\n",
    "                    event.ydata + (ylim[1] - event.ydata) * scale_factor)\n",
    "\n",
    "    ax.set_xlim(xlim_new)\n",
    "    ax.set_ylim(ylim_new)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "def on_motion(event):\n",
    "    \"\"\"Update ring cursor position.\"\"\"\n",
    "    if event.xdata is not None and event.ydata is not None:\n",
    "        circle_outer.set_center((event.xdata, event.ydata))\n",
    "        circle_inner.set_center((event.xdata, event.ydata))\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "def on_motion2(event):\n",
    "    \"\"\"Update ring cursor position.\"\"\"\n",
    "    if event.xdata is not None and event.ydata is not None:\n",
    "        circle.set_center((event.xdata, event.ydata))\n",
    "        circle.set_center((event.xdata, event.ydata))\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "def on_close(event):\n",
    "    \"\"\"Callback function to stop the event loop when the figure is closed.\"\"\"\n",
    "    plt.close()\n",
    "\n",
    "# Display image\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(original_image)\n",
    "ax.set_xlim(xlim_init)\n",
    "ax.set_ylim(ylim_init)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Add quadrant markers\n",
    "ax.text(width/2, height*.9, '1', color='r')\n",
    "ax.text(width*.9, height/2, '2', color='r')\n",
    "ax.text(width/2, height*.1, '3', color='r')\n",
    "ax.text(width*.1, height/2, '4', color='r')\n",
    "ax.set_title(\"Click on markers (in order). Zoom with scroll wheel.\")\n",
    "\n",
    "# Create ring cursor\n",
    "circle_outer = plt.Circle((0, 0), radius=40, color='r', fill=False, lw=2)\n",
    "circle_inner = plt.Circle((0, 0), radius=20, color='r', fill=False, lw=2)\n",
    "ax.add_patch(circle_outer)\n",
    "ax.add_patch(circle_inner)\n",
    "\n",
    "\n",
    "# Connect events\n",
    "fig.canvas.mpl_connect(\"button_press_event\", on_click)\n",
    "fig.canvas.mpl_connect(\"scroll_event\", on_scroll)\n",
    "fig.canvas.mpl_connect(\"motion_notify_event\", on_motion)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3106.461517421706, 3403.8021503327177),\n",
       " (4616.727234909741, 1924.5659905629545),\n",
       " (3132.4174313825924, 420.92588907903246),\n",
       " (1616.1038240720675, 1882.460629651013)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# points = np.array([(3108.1745194618484, 3402.5666577771403),\n",
    "#  (4642.920922553315, 1912.6263830304224),\n",
    "#  (3143.682438629892, 391.1770490488246),\n",
    "#  (1615.726921448857, 1880.5276926742765)])\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this points if you don't want to reassign the points everytime you run the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image\n",
    "points = []  # Store clicked points\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(aligned_checker_image)\n",
    "ax.set_xlim(xlim_init)\n",
    "ax.set_ylim(ylim_init)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Add quadrant markers\n",
    "ax.text(width/2, height*.9, '1', color='r')\n",
    "ax.text(width*.9, height/2, '2', color='r')\n",
    "ax.text(width/2, height*.1, '3', color='r')\n",
    "ax.text(width*.1, height/2, '4', color='r')\n",
    "ax.set_title(\"Click on markers (in order). Zoom with scroll wheel.\")\n",
    "\n",
    "# Create ring cursor\n",
    "circle_outer = plt.Circle((0, 0), radius=40, color='r', fill=False, lw=2)\n",
    "circle_inner = plt.Circle((0, 0), radius=20, color='r', fill=False, lw=2)\n",
    "ax.add_patch(circle_outer)\n",
    "ax.add_patch(circle_inner)\n",
    "\n",
    "\n",
    "# Connect events\n",
    "fig.canvas.mpl_connect(\"button_press_event\", on_click)\n",
    "fig.canvas.mpl_connect(\"scroll_event\", on_scroll)\n",
    "fig.canvas.mpl_connect(\"motion_notify_event\", on_motion)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_checker = np.array(points)\n",
    "points_checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate the camera angle with the known coordinates of the markers.\n",
    "This will break if the order of the coordinates are misaligned. Also notice that the y-axis is inverted when working with images, ensure your know cordinate list is set up accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel locations: [[3108.17451946 3402.56665778]\n",
      " [4642.92092255 1912.62638303]\n",
      " [3143.68243863  391.17704905]\n",
      " [1615.72692145 1880.52769267]]\n",
      "cordinate list: [[3000.         3509.74077919]\n",
      " [4509.74077919 2000.        ]\n",
      " [3000.          490.25922081]\n",
      " [1490.25922081 2000.        ]]\n"
     ]
    }
   ],
   "source": [
    "points_nonaligned    = np.array(points)\n",
    "distance_between_markers_mm = 155.563491 #148.49 # mm 155.669 # \n",
    "distance_between_markers_px0 = np.linalg.norm(points_nonaligned[0] - points_nonaligned[2])\n",
    "distance_between_markers_px1 = np.linalg.norm(points_nonaligned[1] - points_nonaligned[3])\n",
    "# distance_between_markers_px2 = np.sqrt((points_nonaligned[3, 0] - points_nonaligned[1, 0])**2 + (points_nonaligned[3, 1] - points_nonaligned[1, 1])**2)\n",
    "distance_between_markers_px = (distance_between_markers_px0 + distance_between_markers_px1) / 2\n",
    "\n",
    "mm_to_px = distance_between_markers_px/distance_between_markers_mm\n",
    "\n",
    "R_45 = np.array([[0.70710678, -0.70710678], [0.70710678, 0.70710678]])\n",
    "points_aligned0 = np.array([(0, distance_between_markers_mm/2), (distance_between_markers_mm/2, 0), (0, -distance_between_markers_mm/2), (-distance_between_markers_mm/2, 0)])\n",
    "if rotate45:\n",
    "    points_aligned  = points_aligned0 @ R_45 * mm_to_px + np.array([width/2, height/2]) \n",
    "else:\n",
    "    points_aligned  = points_aligned0 * mm_to_px  + np.array([width/2, height/2]) \n",
    "\n",
    "# vertices_pxl = net.vertices_mm_to_pxl(net.vertices, mm_to_px, width, height)\n",
    "\n",
    "print(\"Pixel locations:\", points_nonaligned)\n",
    "print(\"cordinate list:\", points_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21332d40200>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homography_matrix, _ = cv2.findHomography(points_nonaligned, points_aligned, method=cv2.RANSAC)\n",
    "aligned_image = cv2.warpPerspective(original_image, homography_matrix, (width, height))\n",
    "\n",
    "points_aligned_validate = np.array([points_nonaligned[:, 0], points_nonaligned[:, 1], np.ones_like(points_nonaligned[:, 0])])\n",
    "points_aligned_validate = np.dot(homography_matrix, points_aligned_validate)\n",
    "points_aligned_validate = np.array([points_aligned_validate[0, :]/points_aligned_validate[2, :], points_aligned_validate[1, :]/points_aligned_validate[2, :]]).T\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 10), sharex=True, sharey=True)\n",
    "ax[0].imshow(original_image)\n",
    "ax[0].plot(points_nonaligned[:, 0], points_nonaligned[:, 1], 'r-*', markersize=10)\n",
    "ax[0].plot(points_nonaligned[0, 0], points_nonaligned[0, 1], 'bo', markersize=10)\n",
    "ax[0].set_title('Unaligned Image')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(aligned_image)\n",
    "ax[1].plot(points_aligned[:, 0], points_aligned[:, 1], 'r-*', markersize=10, label='known points')\n",
    "ax[1].plot(points_aligned_validate[:, 0], points_aligned_validate[:, 1], 'g.', markersize=10, label='known points - validate')\n",
    "ax[1].plot(points_aligned_validate[0, 0], points_aligned_validate[0, 1], 'bo', markersize=10, label='known points - validate')\n",
    "ax[1].set_title('Orthogonal Image')\n",
    "ax[1].axis('off')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_checker_mm = net.vertices_pxl_to_mm(points_checker, mm_to_px, width, height)\n",
    "points_checker_width0 = np.linalg.norm(points_checker_mm[0] - points_checker_mm[1])\n",
    "points_checker_width1 = np.linalg.norm(points_checker_mm[2] - points_checker_mm[3])\n",
    "points_checker_height0 = np.linalg.norm(points_checker_mm[0] - points_checker_mm[2])\n",
    "points_checker_height1 = np.linalg.norm(points_checker_mm[1] - points_checker_mm[3])\n",
    "print(\"Checkerboard width0:\", points_checker_width0)\n",
    "print(\"Checkerboard width1:\", points_checker_width1)\n",
    "print(\"Checkerboard height0:\", points_checker_height0)\n",
    "print(\"Checkerboard height1:\", points_checker_height1)\n",
    "\n",
    "# aligned_checker_image = cv2.warpPerspective(checker_image, homography_matrix, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1486.98347588,  740.59391419],\n",
       "        [2497.10885361, 1711.73466019],\n",
       "        [2920.78859772, 2098.82164189],\n",
       "        [3305.24668877, 2527.94486701],\n",
       "        [4257.96885529, 3463.42968826],\n",
       "        [1520.00737482, 3498.61991664],\n",
       "        [2494.50186357, 2547.90173932],\n",
       "        [3286.36853102, 1712.08058318],\n",
       "        [4226.30451273,  716.56425979]]),\n",
       " array([[1627.50837496,  627.50837496,    0.        ],\n",
       "        [2625.54358879, 1603.9329701 ,    0.        ],\n",
       "        [3045.36525042, 1994.24573415,    0.        ],\n",
       "        [3425.90774002, 2426.59683857,    0.        ],\n",
       "        [4372.49162504, 3372.49162504,    0.        ],\n",
       "        [1627.50837496, 3372.49162504,    0.        ],\n",
       "        [2613.04640993, 2437.23823329,    0.        ],\n",
       "        [3416.52805704, 1612.32859895,    0.        ],\n",
       "        [4372.49162504,  627.50837496,    0.        ]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices_pxl = net.mm_to_px_using_homography(net.vertices_mm_to_pxl(net.vertices, mm_to_px, width, height), homography_matrix)\n",
    "vertices_pxl_old = net.vertices_mm_to_pxl(net.vertices, mm_to_px, width, height)\n",
    "vertices_pxl, vertices_pxl_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax.axis('off')\n",
    "ax.set_aspect('equal')\n",
    "ax.imshow(aligned_image)\n",
    "# ax.imshow(original_image)\n",
    "ax = net.net_plot_mat(ax, vlabels=True, fp=True, vertices_c = vertices_pxl)\n",
    "\n",
    "circle = plt.Circle((0, 0), radius=4.88*mm_to_px, color='r', fill=False, lw=2)\n",
    "ax.add_patch(circle)\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "fig.canvas.mpl_connect('scroll_event', on_scroll)\n",
    "fig.canvas.mpl_connect(\"motion_notify_event\", on_motion2)\n",
    "fig.canvas.mpl_connect('close_event', on_close)\n",
    "ax.set_title('Click on the vertices of the network (in order). (Scroll to zoom)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-65.8260504 ,  79.65965958],\n",
       "        [-15.72361626,  27.29887419],\n",
       "        [  5.95490148,   6.42326452],\n",
       "        [ 25.75996707, -16.05816129],\n",
       "        [ 77.94899125, -67.97954945],\n",
       "        [-68.89462223, -68.58182186],\n",
       "        [-16.2588883 , -16.32579731],\n",
       "        [ 25.75996707,  25.96069408],\n",
       "        [ 78.75189932,  76.54390214]]),\n",
       " array([[-70.71067812,  70.71067812,   0.        ],\n",
       "        [-19.29196964,  20.40534729,   0.        ],\n",
       "        [  2.33721471,   0.2964594 ,   0.        ],\n",
       "        [ 21.94273871, -21.97824102,   0.        ],\n",
       "        [ 70.71067812, -70.71067812,   0.        ],\n",
       "        [-70.71067812, -70.71067812,   0.        ],\n",
       "        [-19.93582347, -22.52648498,   0.        ],\n",
       "        [ 21.45949806,  19.97280505,   0.        ],\n",
       "        [ 70.71067812,  70.71067812,   0.        ]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.array(points)\n",
    "points_mm = net.vertices_pxl_to_mm(points, mm_to_px, width, height)\n",
    "points_mm, net.vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ftol` termination condition is satisfied.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-70.71067812,  70.71067812,   0.        ],\n",
       "        [-19.29196964,  20.40534729,   0.        ],\n",
       "        [  2.33721471,   0.2964594 ,   0.        ],\n",
       "        [ 21.94273871, -21.97824102,   0.        ],\n",
       "        [ 70.71067812, -70.71067812,   0.        ],\n",
       "        [-70.71067812, -70.71067812,   0.        ],\n",
       "        [-19.93582347, -22.52648498,   0.        ],\n",
       "        [ 21.45949806,  19.97280505,   0.        ],\n",
       "        [ 70.71067812,  70.71067812,   0.        ]]),\n",
       " array([[-65.8260504 ,  79.65965958,   0.        ],\n",
       "        [-19.37670746,  19.98351225,   0.        ],\n",
       "        [  1.8558679 ,  -0.66851265,   0.        ],\n",
       "        [ 21.65569932, -22.90120783,   0.        ],\n",
       "        [ 77.94899125, -67.97954945,   0.        ],\n",
       "        [-68.89462223, -68.58182186,   0.        ],\n",
       "        [-20.46636084, -23.19379039,   0.        ],\n",
       "        [ 21.30458401,  18.96567935,   0.        ],\n",
       "        [ 78.75189932,  76.54390214,   0.        ]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(BYU_UW_root, 'Tensile Testing', 'Avg_Stress_Strain_Overture_TPU_1mm2.csv')\n",
    "stress_data, strain_data = net.load_stress_strain_curve(file_path)\n",
    "strain_to_stress = net.material_model(stress_data, strain_data, interpolation_kind = 'cubic')\n",
    "TPU_nl = {'stress':strain_data, 'strain': stress_data, 'v':0.3897, 'p':1.18e-9, 'A': 0.078294515, 'name': 'TPU Overture'} # TPU Overture non-conductive\n",
    "A = [TPU_nl['A']]*len(net.edges)\n",
    "\n",
    "vertices_equilibrium = np.copy(net.vertices)\n",
    "vertices_equilibrium[net.fixed,:2] = points_mm[net.fixed]\n",
    "\n",
    "vertices_equilibrium, l1_equilibrium, f = net.find_equilibrium(vertices_equilibrium, A, strain_to_stress)\n",
    "vertices_equilibrium_pxl = net.vertices_mm_to_pxl(vertices_equilibrium, mm_to_px, width, height)\n",
    "# net.net_plot(color=False, elables = True, vlabels = False, custom_vertices = vertices_equilibrium)\n",
    "net.vertices, vertices_equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image window closed. `original_image` updated with final transformation.\n"
     ]
    }
   ],
   "source": [
    "# points = []\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax.axis('off')\n",
    "ax.set_aspect('equal')\n",
    "# ax.imshow(aligned_image)\n",
    "ax.imshow(original_image)\n",
    "ax = net.net_plot_mat(ax, vlabels=True, fp=True, vertices_c=vertices_equilibrium_pxl)\n",
    "# ax = net.net_plot_mat(ax, vlabels=True, fp=True, vertices_c=vertices_pxl)\n",
    "# ax.plot(vertices_pxl[net.fixed,0], vertices_pxl[net.fixed,1], 'b*', markersize=5, label='Fixed points - designed')\n",
    "# ax.set_xlim(np.min(vertices_pxl[net.fixed,0]) - 100, np.max(vertices_pxl[net.fixed,0])+ 100)\n",
    "# ax.set_ylim(np.max(vertices_pxl[net.fixed,1])+ 100, np.min(vertices_pxl[net.fixed,1])- 100)\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()\n",
    "# plt.savefig(os.path.join(BYU_UW_root, 'images','validation_images', model_name_im + '_val.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_real = np.array(points)\n",
    "# error_pixels = np.sqrt(np.sum((vertices_real - net.vertices[:, :2])**2, axis=1))\n",
    "error_pixels = np.sqrt(np.sum((vertices_real - vertices_equilibrium[:, :2])**2, axis=1))\n",
    "error_mm = error_pixels / mm_to_px\n",
    "error_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rel = 0\n",
    "for edge_i, edge in enumerate(net.edges):\n",
    "    coor0, coor1 = vertices_real[edge[0]], vertices_real[edge[1]]\n",
    "    l1m = np.linalg.norm(coor0[:2] - coor1[:2])\n",
    "    # error_rel += np.abs(l1m - net.l1[edge_i]) / net.l1[edge_i]\n",
    "    error_rel += np.abs(l1m - l1_equilibrium[edge_i]) / l1_equilibrium[edge_i]\n",
    "# error_rel /= distance_between_markers_mm\n",
    "error_rel/ len(net.edges) # percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.vertices /= mm_to_px # Scale the network vertices to match the image scale\n",
    "net.vertices -= np.array([width/2, height/2,0])\n",
    "\n",
    "# Save the calibration results\n",
    "calibration_results = {\n",
    "    'model_name': model_name,\n",
    "    'model_name_im': model_name_im,\n",
    "    'camera_matrix': mtx,\n",
    "    'distortion_coefficients': dist,\n",
    "    'homography_matrix': homography_matrix,\n",
    "    'real_vertices': points_mm,\n",
    "    'equilibrium_vertices': vertices_equilibrium,\n",
    "    'vertices': net.vertices,\n",
    "    'error_pixels': error_pixels,\n",
    "    'error_mm': error_mm,\n",
    "    'error_rel': error_rel\n",
    "}\n",
    "np.save(os.path.join(BYU_UW_root, 'calibration_results', model_name_im + '_cr.npy'), calibration_results, allow_pickle=True)\n",
    "\n",
    "model_name_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 10), sharey=True)\n",
    "ax[0].set_xlabel('Force (N)')\n",
    "ax[1].set_xlabel('Curvature (1/m)')\n",
    "ax[2].set_xlabel('Initial length (m)')\n",
    "ax[0].set_ylabel('Relative error (%)')\n",
    "\n",
    "calibration_results_files = glob.glob(os.path.join(BYU_UW_root, 'calibration_results', '*_cr.npy'))\n",
    "\n",
    "for file in calibration_results_files:\n",
    "    try:\n",
    "        data = np.load(file, allow_pickle=True).item()\n",
    "    except:\n",
    "        print(f'for some reason {file} stopped working')\n",
    "        continue\n",
    "    model_name_im = data['model_name_im']\n",
    "    model_name = data['model_name']\n",
    "    real_vertices = data['real_vertices']\n",
    "    vertices_equilibrium = data['equilibrium_vertices']\n",
    "\n",
    "    print(model_name)\n",
    "    try:\n",
    "        net2 = Network_custom.load_network(os.path.join(BYU_UW_root, 'networks', model_name + '.pkl'))\n",
    "    except:\n",
    "        net2 = Network_custom.load_network(os.path.join(BYU_UW_root, 'networks', model_name + '_net.pkl')) \n",
    "\n",
    "    f = net2.f\n",
    "    R = net2.R\n",
    "    kappa = 1/R\n",
    "    l0 = net2.l0\n",
    "    error_edge = []\n",
    "    for edge_i, edge in enumerate(net2.edges):\n",
    "        coor0, coor1 = real_vertices[edge[0]], real_vertices[edge[1]]\n",
    "        l1m = np.linalg.norm(coor0[:2] - coor1[:2])\n",
    "        error_edge.append(np.abs(l1m - l1_equilibrium[edge_i]) / l1_equilibrium[edge_i])\n",
    "    edge_error = np.array(error_edge) * 100 # percentage error\n",
    "    ax[0].plot(f, error_edge, 'o', label=model_name_im)\n",
    "    ax[1].plot(kappa, error_edge, 'o', label=model_name_im)\n",
    "    ax[2].plot(l0, error_edge, 'o', label=model_name_im)\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Force vs Relative Error')\n",
    "ax[1].set_title('Curvature vs Relative Error')\n",
    "ax[2].set_title('Initial Length vs Relative Error')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
